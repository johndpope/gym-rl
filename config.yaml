envs:
  cartpole:
    name: CartPole-v0
    num_actions: 2
    state_space: 4
    max_episodes: 500
    win_condition:
      score: 195
      over: 100
  cartpole_v1:
    name: CartPole-v1
    num_actions: 2
    state_space: 4
    max_episodes: 600
    win_condition:
      score: 495
      over: 100
  mountaincar:
    name: MountainCar-v0
    num_actions: 3
    state_space: 2
    max_episodes: 2000
    win_condition:
      score: -110
      over: 100
  lunar:
    name: LunarLander-v2
    num_actions: 4
    state_space: 8
    max_episodes: 4000
    win_condition:
      score: 200
      over: 100
  pong:
    name: Pong-v0
    num_actions: 6
    state_space: 6400
    max_episodes: 1000000
    win_condition:
      score: 20
      over: 1
  pendulum:
    name: Pendulum-v0
    num_actions: 1
    state_space: 3
    max_episodes: 3000
    win_condition:
      score: -150
      over: 100

general:
  test: False
  active_agent: ac-continuous
  active_env: pendulum
  use_win_condition: False

algorithms:
  dqn:
    gamma: .97
    learning_rate: 0.01
    max_memory_size: 50000
    batch_size: 32
    epsilon_start: 1
    epsilon_end: 0.05
    epsilon_decay: 0.999
    cartpole:
      gamma: 1
      max_memory_size: 30000
      epsilon_decay: 0.99
    mountaincar:
      max_memory_size: 10000
  policy:
    learning_rate: 0.01
    gamma: .98
    batch_size: 10
    cartpole:
      learning_rate: 0.1
  actor_critic:
    gamma: .98
    actor_lr: 0.01
    critic_lr: 0.05
    max_memory_size: 10000
    batch_size: 32
  atari-dqn:
    gamma: .99
    learning_rate: 0.001
    batch_size: 32
    epsilon_start: 1
    epsilon_end: 0.05
    epsilon_decay: 0.9999
    max_memory_size: 500000
  atari-policy:
    learning_rate: 0.001
    gamma: .99
    batch_size: 10
  ac_continuous:
    gamma: .9
    actor_lr: 0.001
    critic_lr: 0.005
    max_memory_size: 10000
    batch_size: 32


test:
  use_win_condition: False
  envs:
    - cartpole
#    - mountaincar
#    - lunar
#    - pong
  methods:
#    - dqn
#    - actor_critic
    - policy
#    - atari-policy
  number: 5

log:
  average: 100
  log_every: 10
  log_avg_every: 100
